{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Experimental Setup - Train / Validation / Test Split\n",
    "\n",
    "## Implementation\n",
    "\n",
    "The purpose of this notebook is to obtain perform the train. validation, and test on the GC10-DET for the thesis implementation as outlined in the section 3.2.1 of the bachelor thesis.\n",
    "\n",
    "## Note:\n",
    "\n",
    "- For the initial five scenarios the validation and test sets are merged in one test set. The ratio after this is of 64 / 36 % between train and test sets.\n",
    "\n",
    "- For the Scenario 6, the division of train, validation and test keeps the same."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Importing Dependencies\n",
    "\n",
    "- Importing the necessary libraries to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from class_labels_generator import labels_generator\n",
    "from labels_generator import generate_csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Create a Custom Pytorch Dataset\n",
    "\n",
    "- Defining a custom PyTorch dataset for the split porpuse.\n",
    "- The resizing transformation is already fixed inside the dataset definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitDataset(Dataset):\n",
    "    def __init__(self, labels_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(labels_file, header=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transforms.Resize((224, 224))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = torch.tensor(int(self.annotations.iloc[(index, 2)]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return(image, label)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Spliting the Dataset\n",
    "    \n",
    "- Defining the data ratios.\n",
    "- Defining the data paths.\n",
    "- Defining the dataset classes names and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = (0.8*0.8)            # Defining the train data ration\n",
    "validation_fraction = (0.2*0.8)       # Defining the validation data ratio\n",
    "test_fraction = 0.2                   # Defining the test data ratio\n",
    "proportions = [train_fraction, validation_fraction, test_fraction]\n",
    "\n",
    "raw_path = 'path/to/original/complete/dataset'\n",
    "train_dir = 'path/to/save/raw/training/set'\n",
    "validation_dir = 'path/to/save/validation/set'\n",
    "test_dir = 'path/to/save/test/set'\n",
    "\n",
    "labels_generator(raw_path)\n",
    "\n",
    "classes = [\"0_punching_hole\",\n",
    "           \"1_welding_line\", \n",
    "           \"2_crescent_gap\", \n",
    "           \"3_water_spot\", \n",
    "           \"4_oil_spot\", \n",
    "           \"5_silk_spot\",\n",
    "           \"6_inclusion\", \n",
    "           \"7_rolled_pit\", \n",
    "           \"8_crease\",\n",
    "           \"9_waist_folding\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving the images in a desired folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_creation(dir, type):\n",
    "    \"\"\"Create the folder for each set of the dataset\"\"\"\n",
    "    path = os.path.join(dir, 'images/', type)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def save_images(dataset, type, path, dataset_name):\n",
    "    \"\"\"Save images in the correct folder after split\"\"\"\n",
    "    for idx in range(dataset.__len__()):\n",
    "        img, _ = dataset.__getitem__(idx)\n",
    "        img_name = dataset_name + type + '_' + str(idx) + '.jpg'\n",
    "        img.save(os.path.join(path, img_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performoing the dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type in classes:\n",
    "\n",
    "    file = type + '.csv'\n",
    "\n",
    "    classData = SplitDataset(labels_file=os.path.join(raw_path, file), \n",
    "                        root_dir=os.path.join(raw_path,'images/', type))\n",
    "\n",
    "    lengths = [int(p * len(classData)) for p in proportions]\n",
    "    lengths[-1] = len(classData) - sum(lengths[:-1])\n",
    "\n",
    "    class_split = random_split(classData, lengths, generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    classTrainData = class_split[0]\n",
    "    classValidationData = class_split[1]\n",
    "    classTestData = class_split[2]\n",
    "\n",
    "    #Defining the Folders\n",
    "    train_path = folder_creation(train_dir, type)\n",
    "    validation_path = folder_creation(validation_dir, type)\n",
    "    test_path = folder_creation(test_dir, type)\n",
    "\n",
    "    # Saving the train dataset\n",
    "    save_images(classTrainData, type, train_path, dataset_name=\"train_\")\n",
    "\n",
    "    # Saving the validation dataset\n",
    "    save_images(classValidationData, type, validation_path, dataset_name=\"validation_\")\n",
    "\n",
    "    # Save the test dataset\n",
    "    save_images(classTestData, type, test_path, dataset_name=\"test_\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Generating the label .csv Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving complete labels\n",
    "generate_csv(train_dir)\n",
    "generate_csv(validation_dir)\n",
    "generate_csv(test_dir)\n",
    "\n",
    "# Saving class labels\n",
    "labels_generator(train_dir)\n",
    "labels_generator(validation_dir)\n",
    "labels_generator(test_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_bt_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9540a79c8f4ad311de3552ea9b30a698d4beffab712fced2c9e379c2661abe1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
