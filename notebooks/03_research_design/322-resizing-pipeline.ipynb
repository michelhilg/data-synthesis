{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Extra scenarios on Successful Synthetic Data\n","\n","## Resizing Pipeline - Scenario 6\n","\n","## Implementation\n","\n","The purpose of this notebook is to implement the code for the resizing pipeline on Scenario 6 as outlined in sections 3.2.2 of the bachelor thesis.\n","\n","As a reminder, the Scenario 6 evaluated the impact of the original image size on the classification peformance. Enabling a fair comparision between synthetic and conventional augmented data, this scenario performs a resizing pipeline on original data.\n","\n","The code provided in this notebook was developed using the Kaggle platform."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 1 - Importing Dependencies\n","\n","- Importing the necessary libraries to execute the code."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:16:19.179885Z","iopub.status.busy":"2023-05-04T17:16:19.179334Z","iopub.status.idle":"2023-05-04T17:16:19.188035Z","shell.execute_reply":"2023-05-04T17:16:19.186268Z","shell.execute_reply.started":"2023-05-04T17:16:19.179836Z"},"trusted":true},"outputs":[],"source":["from torchvision.datasets import ImageFolder\n","from torchvision import transforms\n","import os"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 2 - Downsizing the Desired Data\n","\n","- The downsizing of the original data shoukd be applied to:\n","\n","- **Raw Training Dataset**\n","- **Validation Dataset**\n","- **Test Dataset**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Applying the downsizing in the desired dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:16:20.711341Z","iopub.status.busy":"2023-05-04T17:16:20.710883Z","iopub.status.idle":"2023-05-04T17:16:22.720231Z","shell.execute_reply":"2023-05-04T17:16:22.719195Z","shell.execute_reply.started":"2023-05-04T17:16:20.711299Z"},"trusted":true},"outputs":[],"source":["dataset = ImageFolder(root='/path/to/images/root/folder', transform=transforms.Resize((64, 64)))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 3 - Upsizing and Saving\n","\n","- After downsizing, the datasets should be upscaled again to the size of 224x224 pixels.\n","- Then, they should be saved in a specific location."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T17:16:44.486255Z","iopub.status.busy":"2023-05-04T17:16:44.485799Z","iopub.status.idle":"2023-05-04T17:17:41.395403Z","shell.execute_reply":"2023-05-04T17:17:41.393998Z","shell.execute_reply.started":"2023-05-04T17:16:44.486215Z"},"trusted":true},"outputs":[],"source":["path=\"/kaggle/working/04_dcgan_64\"\n","\n","discrete_class = {0 : \"0_punching_hole\",\n","                  1 : \"1_welding_line\",\n","                  2 : \"2_crescent_gap\",\n","                  3 : \"3_water_spot\",\n","                  4 : \"4_oil_spot\",\n","                  5 : \"5_silk_spot\",\n","                  6 : \"6_inclusion\",\n","                  7 : \"7_rolled_pit\",\n","                  8 : \"8_crease\",\n","                  9 : \"9_waist_folding\"}\n","\n","i = 0 \n","for image, label in dataset:\n","    image = transforms.Resize((224, 224))(image)\n","    folder_name = discrete_class[label]\n","    image_name = os.path.basename(f\"Class_{label}_Image_{i}.jpg\")\n","    folder_path = os.path.join(path, folder_name)\n","    os.makedirs(folder_path, exist_ok=True)\n","    image_path = os.path.join(folder_path, image_name)\n","    image.save(image_path)\n","    i += 1"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
