{"cells":[{"attachments":{},"cell_type":"markdown","id":"922d13c3","metadata":{},"source":["# Deep Convolutional Neural Network (DCGAN) - Implementation\n","\n","The purpose of this notebook is to implement the Deep Convolutional Neural Network architecture, as outlined in section 3.4.3 of the bachelor thesis.\n","\n","The code provided in this notebook was developed using the Google Colab platform.\n","\n","The code in this notebook incorporates the following sources as references:\n","\n","- https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"]},{"attachments":{},"cell_type":"markdown","id":"kH6ix8hJde9K","metadata":{"id":"kH6ix8hJde9K"},"source":["## Step 1 - Importing Dependencies\n","\n","- Importing the necessary libraries to execute the code."]},{"cell_type":"code","execution_count":1,"id":"8f5eb58a","metadata":{"executionInfo":{"elapsed":5572,"status":"ok","timestamp":1685778199882,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"8f5eb58a"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from PIL import Image\n","import seaborn as sns"]},{"attachments":{},"cell_type":"markdown","id":"9566fb6a","metadata":{},"source":["## Step 2 - Hyperparameter Settings\n","\n","- Set the HPs for the DCGAN deep generative model. Besides, also check whether a GPU is available for use."]},{"cell_type":"code","execution_count":null,"id":"77c3ddc0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1685778206340,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"77c3ddc0","outputId":"1bd04eee-bdf7-4c47-c319-4d55b8cb8996"},"outputs":[],"source":["torch.manual_seed(999)  # Manual definiton of the seed\n","workers = 2             # Number of workers for dataloader\n","batch_size = 8          # Batch size during training\n","image_size = 64         # Spatial size of training images. All images will be resized to this size using a transformer.\n","nc = 3                  # Number of channels in the training images. For color images, this is 3\n","nz = 100                # Size of z latent vector (i.e., size of generator input)\n","ngf = 64                # Size of feature maps in the generator\n","ndf = 64                # Size of feature maps in the discriminator\n","num_epochs = 800        # Number of training epochs\n","lr = 0.0002             # Learning rate for optimizers\n","beta1 = 0.5             # Beta1 hyperparam for Adam optimizers\n","ngpu = 1                # Number of GPUs available. Use 0 for CPU mode.\n","\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","print(f'Selected device: {device}')"]},{"attachments":{},"cell_type":"markdown","id":"929ccfcc","metadata":{},"source":["- Function to initializing the weights of the DCGAN model as definined in the original whitepaper."]},{"cell_type":"code","execution_count":null,"id":"a4569f81","metadata":{},"outputs":[],"source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"]},{"attachments":{},"cell_type":"markdown","id":"c52b831e","metadata":{"id":"c52b831e"},"source":["## Step 3 - Dataset Loading\n","\n","- Defining the custom class for loading the images as PyTorch dataset."]},{"cell_type":"code","execution_count":4,"id":"03b9dd9d","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1685778211782,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"03b9dd9d"},"outputs":[],"source":["class Dataset(Dataset):\n","    def __init__(self, labels_file, root_dir, transform=None):\n","        self.annotations = pd.read_csv(labels_file, header=None)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.root_dir, str(self.annotations.iloc[index, 1]), self.annotations.iloc[index, 0])\n","        image = Image.open(img_path)\n","        image = image.convert(\"RGB\")\n","        label = torch.tensor(int(self.annotations.iloc[(index, 2)]))\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return(image, label)\n","    \n","    def __getlabel__(self, index):\n","        label = (self.annotations.iloc[(index, 1)])        \n","\n","        return(label)"]},{"attachments":{},"cell_type":"markdown","id":"44c20385","metadata":{},"source":["- The preprocessing transformation matchs the data with the expected format from the DCGAN model.\n","- The labels .cvs file should be passed in a class-wise definiton, since the model is unconditional will generate one class per time."]},{"cell_type":"code","execution_count":null,"id":"82719565","metadata":{"id":"82719565"},"outputs":[],"source":["preprocessing = transforms.Compose([transforms.Resize(image_size), \n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","                                   ])\n","\n","labels_file = '/path/to/class/labels/csv'\n","root_dir = '/path/to/root/image/folder'\n","\n","dataset = Dataset(labels_file=labels_file, root_dir=root_dir, transform=preprocessing)\n","dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=workers)"]},{"attachments":{},"cell_type":"markdown","id":"e61fd71d","metadata":{"id":"e61fd71d"},"source":["## Step 4 - DCGAN Model Definition\n","\n","- **Generator:** Defining the Generator of the DCGAN model, the Generator has the role to create synthetic instances from a noise input."]},{"cell_type":"code","execution_count":11,"id":"ff45dd4c","metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1685778243861,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"ff45dd4c"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Generator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d( nz, ngf * 16, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 16),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d( ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d( ngf * 2, nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)"]},{"cell_type":"code","execution_count":null,"id":"b98acabf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":421,"status":"ok","timestamp":1685778246122,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"b98acabf","outputId":"61370cec-bee1-4797-f3e5-1bfef6f9d8e3"},"outputs":[],"source":["netG = Generator(ngpu).to(device)\n","\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netG = nn.DataParallel(netG, list(range(ngpu)))\n","\n","netG.apply(weights_init)\n","\n","print(netG)"]},{"attachments":{},"cell_type":"markdown","id":"f7e97303","metadata":{"id":"f7e97303"},"source":["- **Discriminator:** Defining the Discriminator of the DCGAN model, the Discriminator has the role of predict whether an image is fake or real."]},{"cell_type":"code","execution_count":13,"id":"b52db24c","metadata":{"executionInfo":{"elapsed":206,"status":"ok","timestamp":1685778248955,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"b52db24c"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)"]},{"cell_type":"code","execution_count":null,"id":"9ee6cada","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":217,"status":"ok","timestamp":1685778251569,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"9ee6cada","outputId":"36641a74-b90d-48b1-a2a2-c815b75b3aad"},"outputs":[],"source":["netD = Discriminator(ngpu).to(device)\n","\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netD = nn.DataParallel(netD, list(range(ngpu)))\n","\n","netD.apply(weights_init)\n","\n","print(netD)"]},{"attachments":{},"cell_type":"markdown","id":"e74c86ec","metadata":{"id":"e74c86ec"},"source":["- Defining the loss function and optimizers for the DCGAN model.\n","- Setting the fixed noise to evaluated the evolution of the DCGAN model over time when training."]},{"cell_type":"code","execution_count":null,"id":"f1d648eb","metadata":{"id":"f1d648eb"},"outputs":[],"source":["criterion = nn.BCELoss()\n","\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n","\n","fixed_noise = torch.randn(224, nz, 1, 1, device=device)\n","real_label = 1.\n","fake_label = 0."]},{"attachments":{},"cell_type":"markdown","id":"2868b301","metadata":{"id":"2868b301"},"source":["## Step 5 - Training the DCGAN\n","\n","- Defining the training loop for the DCGAN, the code also tracks values of interest for future visualization."]},{"cell_type":"code","execution_count":null,"id":"74c643cd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"elapsed":8194,"status":"error","timestamp":1684258604724,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"74c643cd","outputId":"9e3ea05a-5401-4a45-aa2a-1cbb2ab5d298"},"outputs":[],"source":["img_list = []\n","G_losses = []\n","D_losses = []\n","G_losses_epoch = []\n","D_losses_epoch = []\n","iters = 0\n","\n","print(\"Starting Training Loop...\")\n","for epoch in range(num_epochs):\n","    for i, data in enumerate(dataloader, 0):\n","\n","        # (1) Update D network\n","\n","        netD.zero_grad()\n","\n","        real_cpu = data[0].to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","        output = netD(real_cpu).view(-1)\n","\n","        errD_real = criterion(output, label)\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        noise = torch.randn(b_size, nz, 1, 1, device=device)\n","\n","        fake = netG(noise)\n","        label.fill_(fake_label)\n","        output = netD(fake.detach()).view(-1)\n","\n","        errD_fake = criterion(output, label)\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","        errD = errD_real + errD_fake\n","\n","        optimizerD.step()\n","\n","        # (2) Update G network\n","\n","        netG.zero_grad()\n","        label.fill_(real_label)\n","        output = netD(fake).view(-1)\n","\n","        errG = criterion(output, label)\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","\n","        optimizerG.step()\n","\n","        if i % 5 == 0:\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","                  % (epoch, num_epochs, i, len(dataloader),\n","                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        if (iters % 1000 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n","            with torch.no_grad():\n","                fake = netG(fixed_noise).detach().cpu()\n","            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1\n","\n","    G_losses_epoch.append(sum(G_losses)/len(G_losses))\n","    D_losses_epoch.append(sum(D_losses)/len(D_losses))"]},{"attachments":{},"cell_type":"markdown","id":"0Ojh7VYyzTmQ","metadata":{"id":"0Ojh7VYyzTmQ"},"source":["## Step 6 - Visualizing the Results\n","\n","- Visualizing the evolution of the synthetic data created by DCGAN model over epochs."]},{"cell_type":"code","execution_count":null,"id":"33bd53c2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1qOUXF-ORRlcCWjQR-MgI9NMEVFHLw-Mz"},"executionInfo":{"elapsed":25168,"status":"ok","timestamp":1681334237626,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"33bd53c2","outputId":"0c9a8084-9dee-4ae0-dcc5-dca4af083363"},"outputs":[],"source":["fig = plt.figure(figsize=(8,8))\n","plt.axis(\"off\")\n","ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n","ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n","\n","HTML(ani.to_jshtml())"]},{"attachments":{},"cell_type":"markdown","id":"08d365c5","metadata":{},"source":["- Visualizing the Generator and Discriminator loss over epochs."]},{"cell_type":"code","execution_count":null,"id":"M5RpzWvxCzxV","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1681407419297,"user":{"displayName":"Michel Hilgemberg","userId":"08146869376198108831"},"user_tz":-120},"id":"M5RpzWvxCzxV","outputId":"f48fc0a0-4c7a-4e7e-8440-15c39fac6281"},"outputs":[],"source":["sns.set_theme(style=\"whitegrid\")\n","plt.figure(figsize=(10,5))\n","plt.title(\"Generator and discriminator training loss\")\n","plt.plot(G_losses_epoch,label=\"G\")\n","plt.plot(D_losses_epoch,label=\"D\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","id":"4tGfTU7mDeh1","metadata":{"id":"4tGfTU7mDeh1"},"source":["## Step 7 - Saving the Synthetic Images\n","\n","- Defining a fucntion to create a new images based on a noise input.\n","- Saving images in a desired folder location.\n","- Defining the desired number of images in total after the synthetic augmentation\n","- As mentioned, the images are created per class since this is a unconditional implementation."]},{"cell_type":"code","execution_count":null,"id":"a1feadb0","metadata":{"id":"a1feadb0"},"outputs":[],"source":["def save_synthetic_data(dataset, nz, save_path, num_instances):\n","  num_images = num_instances - dataset.__len__()\n","  noise = torch.randn(num_images, nz, 1, 1, device=device)\n","  image_tensor  = netG(noise)\n","  image_list = []\n","  for i in range(image_tensor.size(0)):\n","    tensor_image = image_tensor[i].detach().cpu()\n","    tensor_image = (tensor_image*0.5) + 0.5\n","    pil_image = transforms.ToPILImage()(tensor_image)\n","    pil_image = transforms.Resize((224, 224))(pil_image)\n","    pil_image.save(os.path.join(save_path, dataset.__getlabel__(0), 'dcgan_'+str(dataset.__getlabel__(0))+'_'+str(i)+'.jpg'))\n"]},{"cell_type":"code","execution_count":null,"id":"-IzBF9QTD6RF","metadata":{"id":"-IzBF9QTD6RF"},"outputs":[],"source":["save_path = \"/path/to/save/images/folder\"\n","num_instances = 1000\n","\n","save_synthetic_data(dataset, nz, save_path, num_instances)"]}],"metadata":{"colab":{"collapsed_sections":["olSc-1HudM3_"],"gpuType":"T4","provenance":[{"file_id":"18hlZ_6PTgzdEmsrlvBzw0-2FLqtuDncV","timestamp":1681281537513},{"file_id":"19NWWzPCwUXDZeclu8khU41_vnirSLf_S","timestamp":1678743469235}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":5}
