{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Classification Model - MobileNetV2\n","\n","## Resizing Pipeline - Implementation & Results\n","\n","The purpose of this notebook is to implement the classification model architecture for collecting the results as outlined in section 4.2.3 of the bachelor thesis.\n","\n","The code provided in this notebook was developed using the Kaggle platform.\n","\n","The Scenario 6 definition runs each other scenario from 1 to 5 previous defined. Therefore, its also necessary to specify the desired scenario to run this notebook \n","\n","Please, with you want to run this notebook for scenario 6.5 (scenario 5 defined inside the scenario 6 pipeline), define the variable `scenario` equals to `6.5` below. For any other scenario, especify the varible as `\"other\"`.\n","\n","**OBS.:** The Scenario 6.5 uses a pretrained model on DCGAN synthetic data to perform. Please, make sure to specify the correct path to properly load the model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scenario = \"other\"\n","scenario_5_model_64 = \"path/to/scenario/5/model/64_image_size\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 1 - Set MLFlow & DagsHub\n","\n","- This classification model uses the MlFlow platform for the tracking of the model metrics.\n","- All the information regarding model runs and files is also stored within the MLflow platform.\n","- For hosting the MLFlow server, the notebook uses a DagsHub repository service."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Installing dagshub and MlFlow dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T17:20:27.965543Z","iopub.status.busy":"2023-05-11T17:20:27.964586Z","iopub.status.idle":"2023-05-11T17:20:44.340648Z","shell.execute_reply":"2023-05-11T17:20:44.339334Z","shell.execute_reply.started":"2023-05-11T17:20:27.965497Z"},"trusted":true},"outputs":[],"source":["!pip install --quiet dagshub"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T17:20:44.345401Z","iopub.status.busy":"2023-05-11T17:20:44.345065Z","iopub.status.idle":"2023-05-11T17:21:00.316577Z","shell.execute_reply":"2023-05-11T17:21:00.315432Z","shell.execute_reply.started":"2023-05-11T17:20:44.345363Z"},"trusted":true},"outputs":[],"source":["!pip install --quiet mlflow"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Importing and accessing the DagsHub reposiroty that host the MlFlow server.\n","- If you dont have a DagsHub account you can create one in this [link](https://dagshub.com).\n","- The tutorial about how to connect MlFlow via DagsHub can be founded [here](https://dagshub.com/docs/integration_guide/mlflow_tracking/)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T17:21:00.319699Z","iopub.status.busy":"2023-05-11T17:21:00.319296Z","iopub.status.idle":"2023-05-11T17:21:37.001087Z","shell.execute_reply":"2023-05-11T17:21:37.000130Z","shell.execute_reply.started":"2023-05-11T17:21:00.319661Z"},"trusted":true},"outputs":[],"source":["import dagshub\n","import mlflow\n","\n","dagshub.init(\"your_repo\", \"your_account\", mlflow=True)\n","\n","mlflow.set_tracking_uri('repo_URL + .mlflow')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- **Thesis DagsHub with classification model results is a open repository and could be accessed in the link below:**\n","- [https://dagshub.com/michelhilg/ds_bt_manufacturing](https://dagshub.com/michelhilg/ds_bt_manufacturing)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 2 - Importing Dependencies\n","\n","- Importing the necessary libraries to execute the code."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T17:21:40.715883Z","iopub.status.busy":"2023-05-11T17:21:40.715508Z","iopub.status.idle":"2023-05-11T17:21:53.624724Z","shell.execute_reply":"2023-05-11T17:21:53.623828Z","shell.execute_reply.started":"2023-05-11T17:21:40.715853Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F \n","from torch.utils.data import DataLoader, ConcatDataset\n","from torchvision.datasets import ImageFolder\n","import torchvision.transforms as transforms \n","from torch.optim import Adam\n","from torch.nn.functional import cross_entropy\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import EarlyStopping\n","import torchmetrics\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import mlflow.pytorch"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 3 - Dataset Loading\n","\n","- Util function and preprocessing step in the data following the model definiton."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T17:21:53.626959Z","iopub.status.busy":"2023-05-11T17:21:53.626588Z","iopub.status.idle":"2023-05-11T17:21:53.632487Z","shell.execute_reply":"2023-05-11T17:21:53.631637Z","shell.execute_reply.started":"2023-05-11T17:21:53.626926Z"},"trusted":true},"outputs":[],"source":["def count_instances(dataset):\n","    class_count = {}\n","    for _, label in dataset:\n","        if label in class_count:\n","            class_count[label] += 1\n","        else:\n","            class_count[label] = 1\n","    return class_count\n","\n","preprocessing = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Grayscale(num_output_channels=3),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Building the dataset.\n","- Specify your paths and build the train dataset accordinly with the thesis definition on TABLE 2.\n","- For validation and testing, this model uses two different sets.\n","- **IMPORTANT** - For properly run the Scenario 6 definition, uses the datasets adapted for 64 x 64 image size."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T18:00:57.434515Z","iopub.status.busy":"2023-05-11T18:00:57.433491Z","iopub.status.idle":"2023-05-11T18:00:58.039681Z","shell.execute_reply":"2023-05-11T18:00:58.038642Z","shell.execute_reply.started":"2023-05-11T18:00:57.434477Z"},"trusted":true},"outputs":[],"source":["# Train\n","real_dataset = ImageFolder(root='/path/to/raw/images', transform=preprocessing)\n","extra_dataset = ImageFolder(root='/path/to/augmented/dataset', transform=preprocessing)\n","trainDataset = ConcatDataset([real_dataset, extra_dataset])\n","\n","# Validation\n","valDataset = ImageFolder(root='/path/to/validation/set', transform=preprocessing)\n","\n","# Test\n","testDataset = ImageFolder(root='/path/to/test/set', transform=preprocessing)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Confirming the desired number of instances per class."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T17:22:00.539979Z","iopub.status.busy":"2023-05-11T17:22:00.539539Z","iopub.status.idle":"2023-05-11T17:22:35.949459Z","shell.execute_reply":"2023-05-11T17:22:35.948477Z","shell.execute_reply.started":"2023-05-11T17:22:00.539935Z"},"trusted":true},"outputs":[],"source":["scenario_instances = count_instances(trainDataset)\n","print(f\"Instances per class intances: {scenario_instances}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 4 - MobileNet-V2 Model Definition\n","\n","- Selecting the model based on the scenario definition"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if scenario == 6.5:\n","    model = torch.load(scenario_5_model_64)\n","    model = model.model\n","\n","    for param in model.features.parameters():\n","        param.requires_grad = False\n","\n","else:\n","    model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', weights='IMAGENET1K_V1')\n","\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    model.classifier = nn.Sequential(\n","    nn.Linear(1280, 960),\n","    nn.BatchNorm1d(960),\n","    nn.ReLU(),\n","    nn.Dropout(0.2),\n","    nn.Linear(960, 240),\n","    nn.BatchNorm1d(240),\n","    nn.ReLU(),\n","    nn.Dropout(0.2),\n","    nn.Linear(240, 30),\n","    nn.BatchNorm1d(30),\n","    nn.ReLU(),\n","    nn.Dropout(0.2),\n","    nn.Linear(30, 10)\n","    )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Defining the classification model hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_classes = 10                # Number of classes in the dataset\n","lr = 3e-4                       # Learning rate for the classification model optimizer\n","batch_size=128                  # Batch size for the classification model training\n","seed = np.random.randint(1000)  # Random seed for multiple runs\n","max_epochs = 100                # Maximum number of epochs to train the model\n","num_workers = 2                 # Number of CPU workers to process the data\n","patience = 10                   # Number of epochs of patience for the early stopping"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Defining the classifier class.\n","- Defining the metrics to track during the model training and testing over epochs.\n","- This definition follows the standard of PyTorch Lightning implementation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T18:01:12.820204Z","iopub.status.busy":"2023-05-11T18:01:12.819663Z","iopub.status.idle":"2023-05-11T18:01:12.841312Z","shell.execute_reply":"2023-05-11T18:01:12.840278Z","shell.execute_reply.started":"2023-05-11T18:01:12.820168Z"},"trusted":true},"outputs":[],"source":["class ImageClassifier(pl.LightningModule):\n","    \n","    def __init__(self, seed, num_classes = num_classes, lr = lr, batch_size = batch_size, trainDataset = trainDataset, \n","                 valDataset = valDataset, testDataset = testDataset, model = model):\n","        super().__init__()\n","        \n","        pl.seed_everything(seed)\n","                \n","        self.save_hyperparameters()\n","        \n","        # Datasets\n","        self.trainDataset = trainDataset\n","        self.valDataset = valDataset\n","        self.testDataset = testDataset\n","\n","        # Metrics\n","        self.test_acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n","        self.train_f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='macro')\n","        self.val_f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='macro')\n","        self.test_f1_score_macro = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='macro')\n","        self.test_f1_score_weight = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='weighted')\n","        self.test_precision_macro = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes, average='macro')\n","        self.test_precision_weight = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes, average='weighted')\n","        self.test_recall_macro = torchmetrics.Recall(task=\"multiclass\", num_classes=num_classes, average='macro')\n","        self.test_recall_weight = torchmetrics.Recall(task=\"multiclass\", num_classes=num_classes, average='weighted')  \n","        \n","        # Model\n","        self.model = model\n","        \n","        \n","    def training_step(self, batch, batch_idx):\n","        x, y = batch\n","        \n","        preds = self.model(x)\n","        \n","        loss = cross_entropy(preds, y)\n","        \n","        self.train_f1_score(preds, y)\n","                \n","        self.log('train_loss', loss, on_step=False, on_epoch=True)\n","        self.log('train_f1_score', self.train_f1_score)\n","        \n","        return loss\n","\n","    \n","    def validation_step(self, batch, batch_idx):\n","        x, y = batch\n","        \n","        with torch.no_grad():\n","            preds = self.model(x)\n","        \n","        val_loss = cross_entropy(preds, y)\n","        \n","        self.val_f1_score(preds, y)\n","        \n","        self.log('val_loss', val_loss)\n","        self.log('val_f1_score', self.val_f1_score)\n","        \n","        return val_loss\n","    \n","    \n","    def test_step(self, batch, batch_idx):\n","        x, y = batch\n","        \n","        with torch.no_grad():\n","            preds = self.model(x)\n","                \n","        self.test_acc(preds, y)\n","        self.test_f1_score_macro(preds, y)\n","        self.test_f1_score_weight(preds, y)\n","        self.test_precision_macro(preds, y)\n","        self.test_precision_weight(preds, y)\n","        self.test_recall_macro(preds, y)\n","        self.test_recall_weight(preds, y)\n","        \n","        self.log('test_acc', self.test_acc)\n","        self.log('test_f1_score_macro', self.test_f1_score_macro)\n","        self.log('test_f1_score_weight', self.test_f1_score_weight)\n","        self.log('test_precision_macro', self.test_precision_macro)\n","        self.log('test_precision_weight', self.test_precision_weight)\n","        self.log('test_recall_macro', self.test_recall_macro)\n","        self.log('test_recall_weight', self.test_recall_weight)\n","        \n","    \n","    def configure_optimizers(self):\n","        classifier_params = list(self.model.classifier.parameters())\n","        optimizer = Adam(classifier_params, lr=self.hparams.lr)\n","        return optimizer\n","    \n","    \n","    def train_dataloader(self):\n","        return DataLoader(dataset=self.trainDataset, batch_size=self.hparams.batch_size, shuffle=True, num_workers=num_workers)\n","     \n","        \n","    def val_dataloader(self):\n","        return DataLoader(dataset=self.valDataset, batch_size=self.hparams.batch_size, num_workers=num_workers)\n","    \n","    \n","    def test_dataloader(self):\n","        return DataLoader(dataset=self.testDataset, batch_size=self.hparams.batch_size, num_workers=num_workers)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 5 - Training the MobileNet-V2 Classification Model\n","\n","- The MlFlow experiment and run are defined below, select your desired name. If you want to load new runs inside a experiment that already has been created, just define the `experiment_name` accordingly.\n","- The training is conduct using PyTorch Lightning tools and all the desired metrics are tracked with MlFlow.\n","- This training pipeline used a early stopping technique monitoring the validation loss value."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T18:01:15.854651Z","iopub.status.busy":"2023-05-11T18:01:15.854251Z","iopub.status.idle":"2023-05-11T18:08:00.164104Z","shell.execute_reply":"2023-05-11T18:08:00.163048Z","shell.execute_reply.started":"2023-05-11T18:01:15.854617Z"},"trusted":true},"outputs":[],"source":["experiment_name = \"Name of the experiment to be track with MlFlow\"\n","run_name = f\"Name of the run, usually declaring the {seed}\"\n","\n","try:\n","    experiment_id = mlflow.create_experiment(experiment_name)\n","except:\n","    current_experiment = dict(mlflow.get_experiment_by_name(experiment_name))\n","    experiment_id = current_experiment['experiment_id']\n","\n","early_stopping = EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\")\n","\n","classifier = ImageClassifier(seed=seed)\n","\n","trainer = pl.Trainer(max_epochs=max_epochs, \n","                     log_every_n_steps=6,\n","                     callbacks=[early_stopping],\n","                     accelerator='gpu',\n","                     devices=1)\n","\n","mlflow.pytorch.autolog()\n","\n","with mlflow.start_run(experiment_id=experiment_id, run_name=run_name) as run:\n","    trainer.fit(classifier)\n","    trainer.test(classifier)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
