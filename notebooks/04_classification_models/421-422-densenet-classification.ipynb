{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Classification Model - DensetNet201 - Initial Experimental Setup & Pre-trained Model - Implementation & Results\n","\n","The purpose of this notebook is to implement the classification model architecture for collecting the results as outlined in section 4.2.1 and 4.2.2 of the bachelor thesis.\n","\n","The code provided in this notebook was developed using the Kaggle platform.\n","\n","Please, with you want to run this notebook for scenario 5, define the variable `scenario` equals to `5` below. For any other scenario, especify the varible as `\"other\"`.\n","\n","**OBS.:** The Scenario 5 uses a pretrained model on DCGAN synthetic data to perform. Please, make sure to specify the correct path to properly load the model."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["scenario = \"other\"\n","scenario_5_model = \"path/to/scenario/5/model\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 1 - Set MLFlow & DagsHub\n","\n","- This classification model uses the MlFlow platform for the tracking of the model metrics.\n","- All the information regarding model runs and files is also stored within the MLflow platform.\n","- For hosting the MLFlow server, the notebook uses a DagsHub repository service."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Installing dagshub and MlFlow dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-12T06:55:00.964450Z","iopub.status.busy":"2023-05-12T06:55:00.963814Z","iopub.status.idle":"2023-05-12T06:55:19.567529Z","shell.execute_reply":"2023-05-12T06:55:19.566255Z","shell.execute_reply.started":"2023-05-12T06:55:00.964405Z"},"trusted":true},"outputs":[],"source":["!pip install --quiet dagshub"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-12T06:55:19.571675Z","iopub.status.busy":"2023-05-12T06:55:19.571080Z","iopub.status.idle":"2023-05-12T06:55:36.121118Z","shell.execute_reply":"2023-05-12T06:55:36.119877Z","shell.execute_reply.started":"2023-05-12T06:55:19.571637Z"},"trusted":true},"outputs":[],"source":["!pip install --quiet mlflow"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Importing and accessing the DagsHub reposiroty that host the MlFlow server.\n","- If you dont have a DagsHub account you can create one in this [link](https://dagshub.com).\n","- The tutorial about how to connect MlFlow via DagsHub can be founded [here](https://dagshub.com/docs/integration_guide/mlflow_tracking/)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-12T06:55:36.123934Z","iopub.status.busy":"2023-05-12T06:55:36.123530Z","iopub.status.idle":"2023-05-12T06:56:07.146294Z","shell.execute_reply":"2023-05-12T06:56:07.145041Z","shell.execute_reply.started":"2023-05-12T06:55:36.123886Z"},"trusted":true},"outputs":[],"source":["import dagshub\n","import mlflow\n","\n","dagshub.init(\"your_repo\", \"your_account\", mlflow=True)\n","\n","mlflow.set_tracking_uri('repo_URL + .mlflow')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- **Thesis DagsHub with classification model results is a open repository and could be accessed in the link below:**\n","- [https://dagshub.com/michelhilg/ds_bt_manufacturing](https://dagshub.com/michelhilg/ds_bt_manufacturing)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 2 - Importing Dependencies\n","\n","- Importing the necessary libraries to execute the code."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-12T06:56:13.852433Z","iopub.status.busy":"2023-05-12T06:56:13.851907Z","iopub.status.idle":"2023-05-12T06:56:20.983399Z","shell.execute_reply":"2023-05-12T06:56:20.982281Z","shell.execute_reply.started":"2023-05-12T06:56:13.852380Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","import torchvision \n","import torch.nn.functional as F \n","import torch.nn.init as init\n","\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset, SubsetRandomSampler\n","from torchvision.datasets import ImageFolder\n","import torchvision.transforms as transforms \n","\n","from torch.optim import Adam\n","from torch.nn.functional import cross_entropy\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import EarlyStopping\n","import torchmetrics\n","\n","import random\n","import pandas as pd\n","import os\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import mlflow.pytorch\n","from mlflow import MlflowClient"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 3 - Dataset Loading\n","\n","- Util function and preprocessing step in the data following the model definiton."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-12T06:56:20.986291Z","iopub.status.busy":"2023-05-12T06:56:20.985905Z","iopub.status.idle":"2023-05-12T06:56:20.993441Z","shell.execute_reply":"2023-05-12T06:56:20.992280Z","shell.execute_reply.started":"2023-05-12T06:56:20.986246Z"},"trusted":true},"outputs":[],"source":["def count_instances(dataset):\n","    class_count = {}\n","    for _, label in dataset:\n","        if label in class_count:\n","            class_count[label] += 1\n","        else:\n","            class_count[label] = 1\n","    return class_count\n","\n","preprocessing = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Grayscale(num_output_channels=3),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Building the dataset.\n","- Specify your paths and build the train dataset accordinly with the thesis definition on TABLE 2.\n","- For testing, this classification uses the 64 / 36 % split ratio, with validation and test datasets combined in one test set."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-12T06:56:21.006754Z","iopub.status.busy":"2023-05-12T06:56:21.005873Z","iopub.status.idle":"2023-05-12T06:56:30.633964Z","shell.execute_reply":"2023-05-12T06:56:30.632566Z","shell.execute_reply.started":"2023-05-12T06:56:21.006715Z"},"trusted":true},"outputs":[],"source":["# Train\n","real_dataset = ImageFolder(root='/kaggle/input/gc10-det/02_raw_train/images', transform=preprocessing)\n","extra_dataset = ImageFolder(root='/kaggle/input/04-dcgan/04_dcgan/images', transform=preprocessing)\n","trainDataset = ConcatDataset([real_dataset, extra_dataset])\n","\n","# Validation/Test\n","valDataset_1 = ImageFolder(root='/kaggle/input/98-validation/98_validation/images', transform=preprocessing)\n","valDataset_2 = ImageFolder(root='/kaggle/input/99-test/99_test/images', transform=preprocessing)\n","valDataset = ConcatDataset([valDataset_1, valDataset_2])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Confirming the desired number of instances per class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-11T17:05:45.615485Z","iopub.status.busy":"2023-05-11T17:05:45.615011Z","iopub.status.idle":"2023-05-11T17:06:30.893633Z","shell.execute_reply":"2023-05-11T17:06:30.892318Z","shell.execute_reply.started":"2023-05-11T17:05:45.615428Z"},"trusted":true},"outputs":[],"source":["scenario_instances = count_instances(trainDataset)\n","print(f\"Instances per class intances: {scenario_instances}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 4 - DenseNet201 Model Definition\n","\n","- Selecting the model based on the scenario definition"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if scenario == 5:\n","    model = torch.load(scenario_5_model)\n","    model = model.model\n","\n","else:\n","    model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', weights='IMAGENET1K_V1')\n","\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    model.classifier = nn.Sequential(\n","    nn.Linear(1920, 960),\n","    nn.BatchNorm1d(960),\n","    nn.ReLU(),\n","    nn.Dropout(0.2),\n","    nn.Linear(960, 240),\n","    nn.BatchNorm1d(240),\n","    nn.ReLU(),\n","    nn.Dropout(0.2),\n","    nn.Linear(240, 30),\n","    nn.BatchNorm1d(30),\n","    nn.ReLU(),\n","    nn.Dropout(0.2),\n","    nn.Linear(30, 10)\n","    )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Defining the classification model hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_classes = 10                # Number of classes in the dataset\n","lr = 3e-4                       # Learning rate for the classification model optimizer\n","batch_size=128                  # Batch size for the classification model training\n","seed = np.random.randint(1000)  # Random seed for multiple runs\n","max_epochs = 75                 # Maximum number of epochs to train the model"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["- Defining the classifier class.\n","- Defining the metrics to track during the model training and testing over epochs.\n","- This definition follows the standard of PyTorch Lightning implementation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-12T06:56:34.002530Z","iopub.status.busy":"2023-05-12T06:56:34.002127Z","iopub.status.idle":"2023-05-12T06:56:34.026738Z","shell.execute_reply":"2023-05-12T06:56:34.025346Z","shell.execute_reply.started":"2023-05-12T06:56:34.002491Z"},"trusted":true},"outputs":[],"source":["class ImageClassifier(pl.LightningModule):\n","    \n","    def __init__(self, seed, num_classes = num_classes, lr = lr, batch_size = batch_size, trainDataset = trainDataset, \n","                 valDataset = valDataset, model = model):\n","        super().__init__()\n","        \n","        pl.seed_everything(seed)\n","                \n","        self.save_hyperparameters()\n","        \n","        # Datasets\n","        self.trainDataset = trainDataset\n","        self.valDataset = valDataset\n","\n","        # Metrics\n","        # Train\n","        self.train_f1_score_macro = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='macro')\n","        self.train_f1_score_weight = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='weighted')\n","        # Test\n","        self.test_acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n","        self.test_f1_score_macro = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='macro')\n","        self.test_f1_score_weight = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='weighted')\n","        self.test_precision_macro = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes, average='macro')\n","        self.test_precision_weight = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes, average='weighted')\n","        self.test_recall_macro = torchmetrics.Recall(task=\"multiclass\", num_classes=num_classes, average='macro')\n","        self.test_recall_weight = torchmetrics.Recall(task=\"multiclass\", num_classes=num_classes, average='weighted')  \n","        \n","        self.model = model\n","        \n","        \n","    def training_step(self, batch, batch_idx):\n","        x, y = batch\n","        \n","        preds = self.model(x)\n","        \n","        loss = cross_entropy(preds, y)\n","        \n","        self.train_f1_score_macro(preds, y)\n","        self.train_f1_score_weight(preds, y)\n","                \n","        self.log('train_loss', loss, on_step=False, on_epoch=True)\n","        self.log('train_f1_score_macro', self.train_f1_score_macro)\n","        self.log('train_f1_score_weight', self.train_f1_score_weight)\n","        \n","        return loss\n","\n","    \n","    def validation_step(self, batch, batch_idx):\n","        x, y = batch\n","        \n","        with torch.no_grad():\n","            preds = self.model(x)\n","        \n","        test_loss = cross_entropy(preds, y)\n","                \n","        self.log('test_loss', test_loss)\n","        \n","        self.test_acc(preds, y)\n","        self.test_f1_score_macro(preds, y)\n","        self.test_f1_score_weight(preds, y)\n","        self.test_precision_macro(preds, y)\n","        self.test_precision_weight(preds, y)\n","        self.test_recall_macro(preds, y)\n","        self.test_recall_weight(preds, y)\n","        \n","        self.log('test_acc', self.test_acc)\n","        self.log('test_f1_score_macro', self.test_f1_score_macro, on_step=False, on_epoch=True)\n","        self.log('test_f1_score_weight', self.test_f1_score_weight, on_step=False, on_epoch=True)\n","        self.log('test_precision_macro', self.test_precision_macro, on_step=False, on_epoch=True)\n","        self.log('test_precision_weight', self.test_precision_weight, on_step=False, on_epoch=True)\n","        self.log('test_recall_macro', self.test_recall_macro)\n","        self.log('test_recall_weight', self.test_recall_weight)\n","        \n","        return test_loss\n","    \n","\n","    def configure_optimizers(self):\n","        classifier_params = list(self.model.classifier.parameters())\n","        optimizer = Adam(classifier_params, lr=self.hparams.lr)\n","        return optimizer\n","    \n","    \n","    def train_dataloader(self):\n","        return DataLoader(dataset=self.trainDataset, batch_size=self.hparams.batch_size, shuffle=True, num_workers=2)\n","     \n","        \n","    def val_dataloader(self):\n","        return DataLoader(dataset=self.valDataset, batch_size=self.hparams.batch_size, num_workers=2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Step 5 - Training the DensetNet201 Classification Model\n","\n","- The MlFlow experiment and run are defined below, select your desired name. If you want to load new runs inside a experiment that already has been created, just define the `experiment_name` accordingly.\n","- The training is conduct using PyTorch Lightning tools and all the desired metrics are tracked with MlFlow."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-12T06:56:34.028673Z","iopub.status.busy":"2023-05-12T06:56:34.028290Z","iopub.status.idle":"2023-05-12T07:50:11.590489Z","shell.execute_reply":"2023-05-12T07:50:11.589279Z","shell.execute_reply.started":"2023-05-12T06:56:34.028626Z"},"trusted":true},"outputs":[],"source":["experiment_name = \"Name of the experiment to be track with MlFlow\"\n","run_name = f\"Name of the run, usually declaring the {seed}\"\n","\n","try:\n","    experiment_id = mlflow.create_experiment(experiment_name)\n","except:\n","    current_experiment = dict(mlflow.get_experiment_by_name(experiment_name))\n","    experiment_id = current_experiment['experiment_id']\n","\n","classifier = ImageClassifier(seed=seed)\n","\n","trainer = pl.Trainer(max_epochs=max_epochs, \n","                     log_every_n_steps=6,\n","                     accelerator='gpu',\n","                     devices=1)\n","\n","mlflow.pytorch.autolog()\n","\n","with mlflow.start_run(experiment_id=experiment_id, run_name=run_name) as run:\n","    trainer.fit(classifier)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
